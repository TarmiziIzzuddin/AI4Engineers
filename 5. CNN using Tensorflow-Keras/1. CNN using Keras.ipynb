{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<p align=\"center\"><img src=\"https://www.utem.edu.my/templates/yootheme/cache/03/LogoUTeM-03999b95.png\" width=\"300\"></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h1 align=center>Convolutional Neural Networks with Keras</h1>\n",
    "<h4>About this Notebook</h4>\n",
    "In this lab, we will learn how to use the Keras library to build convolutional neural networks. We will also use the popular MNIST dataset and we will compare our results to using a conventional neural network.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Keras and Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by importing the keras libraries and the packages that we would need to build a neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When working with convolutional neural networks in particular, we will need additional packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D # to add convolutional layers\n",
    "from tensorflow.keras.layers import MaxPooling2D # to add pooling layers\n",
    "from tensorflow.keras.layers import Flatten # to flatten data for fully connected layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Layer with One set of convolutional and pooling layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "from keras.datasets import mnist\n",
    "\n",
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# reshape to be [samples][pixels][width][height]\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's normalize the pixel values to be between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255 # normalize training data\n",
    "X_test = X_test / 255 # normalize test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's convert the target variable into binary categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "num_classes = y_test.shape[1] # number of categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's define a function that creates our model. Let's start with one set of convolutional and pooling layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_model_1():\n",
    "    \n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, (5, 5), strides=(1, 1), activation='relu', input_shape=(28, 28, 1)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    # compile model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy',  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's call the function to create the model, and then let's train it and evaluate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_8 (Conv2D)           (None, 24, 24, 16)        416       \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 12, 12, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 2304)              0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 100)               230500    \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 231,926\n",
      "Trainable params: 231,926\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "300/300 - 2s - loss: 0.3006 - accuracy: 0.9136 - val_loss: 0.1170 - val_accuracy: 0.9661 - 2s/epoch - 5ms/step\n",
      "Epoch 2/10\n",
      "300/300 - 1s - loss: 0.0967 - accuracy: 0.9716 - val_loss: 0.0675 - val_accuracy: 0.9790 - 1s/epoch - 3ms/step\n",
      "Epoch 3/10\n",
      "300/300 - 1s - loss: 0.0642 - accuracy: 0.9810 - val_loss: 0.0520 - val_accuracy: 0.9823 - 996ms/epoch - 3ms/step\n",
      "Epoch 4/10\n",
      "300/300 - 1s - loss: 0.0487 - accuracy: 0.9861 - val_loss: 0.0483 - val_accuracy: 0.9842 - 1s/epoch - 3ms/step\n",
      "Epoch 5/10\n",
      "300/300 - 1s - loss: 0.0405 - accuracy: 0.9879 - val_loss: 0.0390 - val_accuracy: 0.9870 - 1s/epoch - 3ms/step\n",
      "Epoch 6/10\n",
      "300/300 - 1s - loss: 0.0320 - accuracy: 0.9905 - val_loss: 0.0395 - val_accuracy: 0.9875 - 1s/epoch - 3ms/step\n",
      "Epoch 7/10\n",
      "300/300 - 1s - loss: 0.0263 - accuracy: 0.9924 - val_loss: 0.0396 - val_accuracy: 0.9865 - 1s/epoch - 4ms/step\n",
      "Epoch 8/10\n",
      "300/300 - 1s - loss: 0.0220 - accuracy: 0.9933 - val_loss: 0.0386 - val_accuracy: 0.9857 - 1s/epoch - 4ms/step\n",
      "Epoch 9/10\n",
      "300/300 - 1s - loss: 0.0189 - accuracy: 0.9942 - val_loss: 0.0372 - val_accuracy: 0.9876 - 1s/epoch - 4ms/step\n",
      "Epoch 10/10\n",
      "300/300 - 1s - loss: 0.0146 - accuracy: 0.9958 - val_loss: 0.0397 - val_accuracy: 0.9877 - 1s/epoch - 4ms/step\n",
      "Accuracy: 0.9876999855041504 \n",
      " Error: 1.230001449584961\n"
     ]
    }
   ],
   "source": [
    "# build the model\n",
    "model = convolutional_model_1()\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)\n",
    "\n",
    "# evaluate the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: {} \\n Error: {}\".format(scores[1], 100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Layer with two sets of convolutional and pooling layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's redefine our convolutional model so that it has two convolutional and pooling layers instead of just one layer of each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_model_2():\n",
    "    \n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, (5, 5), activation='relu', input_shape=(28, 28, 1)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(8, (2, 2), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy',  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's call the function to create our new convolutional neural network, and then let's train it and evaluate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_9 (Conv2D)           (None, 24, 24, 16)        416       \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 12, 12, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 11, 11, 8)         520       \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 5, 5, 8)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 200)               0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 100)               20100     \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22,046\n",
      "Trainable params: 22,046\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "300/300 - 2s - loss: 0.4621 - accuracy: 0.8712 - val_loss: 0.1223 - val_accuracy: 0.9639 - 2s/epoch - 6ms/step\n",
      "Epoch 2/10\n",
      "300/300 - 1s - loss: 0.1067 - accuracy: 0.9683 - val_loss: 0.0736 - val_accuracy: 0.9777 - 1s/epoch - 4ms/step\n",
      "Epoch 3/10\n",
      "300/300 - 1s - loss: 0.0767 - accuracy: 0.9768 - val_loss: 0.0598 - val_accuracy: 0.9811 - 1s/epoch - 4ms/step\n",
      "Epoch 4/10\n",
      "300/300 - 1s - loss: 0.0646 - accuracy: 0.9806 - val_loss: 0.0535 - val_accuracy: 0.9836 - 1s/epoch - 4ms/step\n",
      "Epoch 5/10\n",
      "300/300 - 1s - loss: 0.0569 - accuracy: 0.9829 - val_loss: 0.0463 - val_accuracy: 0.9854 - 1s/epoch - 4ms/step\n",
      "Epoch 6/10\n",
      "300/300 - 1s - loss: 0.0490 - accuracy: 0.9858 - val_loss: 0.0408 - val_accuracy: 0.9862 - 1s/epoch - 4ms/step\n",
      "Epoch 7/10\n",
      "300/300 - 1s - loss: 0.0441 - accuracy: 0.9870 - val_loss: 0.0392 - val_accuracy: 0.9872 - 1s/epoch - 4ms/step\n",
      "Epoch 8/10\n",
      "300/300 - 1s - loss: 0.0397 - accuracy: 0.9882 - val_loss: 0.0395 - val_accuracy: 0.9870 - 1s/epoch - 4ms/step\n",
      "Epoch 9/10\n",
      "300/300 - 1s - loss: 0.0367 - accuracy: 0.9890 - val_loss: 0.0348 - val_accuracy: 0.9881 - 1s/epoch - 4ms/step\n",
      "Epoch 10/10\n",
      "300/300 - 1s - loss: 0.0337 - accuracy: 0.9902 - val_loss: 0.0338 - val_accuracy: 0.9890 - 1s/epoch - 4ms/step\n",
      "Accuracy: 0.9890000224113464 \n",
      " Error: 1.0999977588653564\n"
     ]
    }
   ],
   "source": [
    "# build the model\n",
    "model = convolutional_model_2()\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)\n",
    "\n",
    "# evaluate the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: {} \\n Error: {}\".format(scores[1], 100-scores[1]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('myenv1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a0cb3063e4d1817848e0611c0ec90460e2ed4e0f6f83c33189da7391ee5fceee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
